{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "95793ae7-7075-4cc2-a965-51151f19520a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout, Input\n",
    "from tensorflow.keras.optimizers import Adam, SGD, RMSprop\n",
    "from tensorflow.keras.regularizers import l2\n",
    "from keras.regularizers import l2\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "from torchvision import transforms\n",
    "from tensorflow.keras.callbacks import History\n",
    "import torch.nn.functional as F\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5eda5785-623d-4e3f-aefc-b287f4f10411",
   "metadata": {},
   "source": [
    "# Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "6f2b2dab-4dc7-4e24-b018-3535468e4fe9",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('train.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "3447f10b-eb03-45ba-8813-04b3cca644fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = data.drop('label', axis=1).values\n",
    "y = data['label'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "7812c489-862e-4a79-a15c-5576eb728a20",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_tes, y_train, y_tes = train_test_split(X, y, test_size=0.2, random_state=42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "ffb15184-f770-4546-a1d6-f37f531ba7e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test, X_val, y_test, y_val = train_test_split(X_tes, y_tes, test_size=0.5, random_state=42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "891e3e01-a40c-4dd5-80ba-2fd1f287438a",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_r = X_train.reshape(-1, 1, 32, 32) / 255.0\n",
    "X_val_r = X_val.reshape(-1, 1, 32, 32) / 255.0\n",
    "X_test_r = X_test.reshape(-1, 1, 32, 32) / 255.0 #normalizing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "93df0b1a-8913-4cd5-a57a-b64a50ffae30",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_tensor = TensorDataset(torch.Tensor(X_train_r), torch.Tensor(y_train).long())\n",
    "val_tensor = TensorDataset(torch.Tensor(X_val_r), torch.Tensor(y_val).long())\n",
    "test_tensor = TensorDataset(torch.Tensor(X_test_r), torch.Tensor(y_test).long())\n",
    "\n",
    "#train test val tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "00cf0a08-3925-42b3-9e9b-513f34cd888c",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = DataLoader(train_tensor, batch_size=64, shuffle=True)\n",
    "val_loader = DataLoader(val_tensor, batch_size=64, shuffle=False)\n",
    "test_loader = DataLoader(test_tensor, batch_size=64, shuffle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9e7244a-b3fb-483d-8327-ee4e2799e452",
   "metadata": {},
   "source": [
    "# Final model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "0338397d-8f7f-460d-b13d-4276ea9080f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomCNN(nn.Module):\n",
    "    def __init__(self, layers):\n",
    "        super(CustomCNN, self).__init__()\n",
    "        self.layers = nn.ModuleList()\n",
    "        input_channels = 1  \n",
    "\n",
    "        for output_channels in layers:\n",
    "            self.layers.append(nn.Conv2d(input_channels, output_channels, kernel_size=3, padding=1))\n",
    "            self.layers.append(nn.ReLU())\n",
    "            self.layers.append(nn.MaxPool2d(2))\n",
    "            input_channels = output_channels\n",
    "\n",
    "        # classification layer\n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.Flatten(),\n",
    "            nn.Linear(input_channels * (32 // 2**len(layers))**2, 128),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(128, 10)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        for layer in self.layers:\n",
    "            x = layer(x)\n",
    "        x = self.classifier(x)\n",
    "        return x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f1c2aa81-dfa5-4d2a-b381-7da347f3c863",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = CustomCNN([64, 128])\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)  # Adam with best learning rate\n",
    "criterion = nn.CrossEntropyLoss()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "26dcd6e5-4aae-4237-ac84-d321d81f7779",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_and_validate(model, train_loader, val_loader, optimizer, criterion, epochs):\n",
    "    model.train()\n",
    "    for epoch in range(epochs):\n",
    "        for inputs, labels in train_loader:\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "        print(f'Epoch {epoch + 1}/{epochs} training complete.')\n",
    "\n",
    "    \n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        val_loss = 0\n",
    "        correct = 0\n",
    "        total = 0\n",
    "        for inputs, labels in val_loader:\n",
    "            outputs = model(inputs)\n",
    "            val_loss += criterion(outputs, labels).item()\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "\n",
    "        val_accuracy = 100 * correct / total\n",
    "        print(f'Validation Accuracy: {val_accuracy:.2f}%')\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ca881646-8378-4ff1-8936-27937811a01f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10 training complete.\n",
      "Epoch 2/10 training complete.\n",
      "Epoch 3/10 training complete.\n",
      "Epoch 4/10 training complete.\n",
      "Epoch 5/10 training complete.\n",
      "Epoch 6/10 training complete.\n",
      "Epoch 7/10 training complete.\n",
      "Epoch 8/10 training complete.\n",
      "Epoch 9/10 training complete.\n",
      "Epoch 10/10 training complete.\n",
      "Validation Accuracy: 90.21%\n"
     ]
    }
   ],
   "source": [
    "final_model = train_and_validate(model, train_loader, val_loader, optimizer, criterion, epochs=10)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "2b630130-ab15-4ee0-b949-7c67a82596b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# saving trained model\n",
    "torch.save(final_model.state_dict(), 'final_best_model.pth')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7349cbb3-16f5-4f95-8e4f-424b76fb77a1",
   "metadata": {},
   "source": [
    "# Test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "71fcad16-b711-401a-a5a9-c86d2eea9df4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CustomCNN(\n",
       "  (layers): ModuleList(\n",
       "    (0): Conv2d(1, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (1): ReLU()\n",
       "    (2): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (3): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (4): ReLU()\n",
       "    (5): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "  )\n",
       "  (classifier): Sequential(\n",
       "    (0): Flatten(start_dim=1, end_dim=-1)\n",
       "    (1): Linear(in_features=8192, out_features=128, bias=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=128, out_features=10, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = CustomCNN([64, 128])\n",
    "\n",
    "#weights\n",
    "model.load_state_dict(torch.load('final_best_model.pth'))\n",
    "\n",
    "# evaluation\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "372592e8-7e1d-4e5a-926e-e9a6198e4de8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_model(model, data_loader):\n",
    "    model.eval()  # Перевод модели в режим оценки\n",
    "    total = 0\n",
    "    correct = 0\n",
    "    total_loss = 0.0\n",
    "    criterion = torch.nn.CrossEntropyLoss()  # Использование CrossEntropyLoss для классификации\n",
    "\n",
    "    with torch.no_grad():  # Отключение градиентов для ускорения вычислений\n",
    "        for inputs, labels in data_loader:\n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs, labels)\n",
    "            total_loss += loss.item() * inputs.size(0)\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "            total += labels.size(0)\n",
    "\n",
    "    avg_loss = total_loss / total\n",
    "    accuracy = 100 * correct / total\n",
    "    return avg_loss, accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "a53fa19d-26e8-4703-b519-75982a25fa93",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_loss, test_accuracy = evaluate_model(model, test_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "8360e6cb-a286-475e-bfc6-2abb563ea6b5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Loss: 0.3138\n",
      "Test Accuracy: 90.25%\n"
     ]
    }
   ],
   "source": [
    "print(f'Test Loss: {test_loss:.4f}')\n",
    "print(f'Test Accuracy: {test_accuracy:.2f}%')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71a4d9cd-1cb9-4c55-902b-3a1a2a1c6430",
   "metadata": {},
   "source": [
    "Model's perfomance on test data is 90%"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb7d4c1f-4f4d-4b0f-bb82-79e7f94eb9a8",
   "metadata": {},
   "source": [
    "# Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "aba2a030-3afd-44b5-80cc-831a29d5b62a",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data = pd.read_csv('evaluate.csv')\n",
    "X_test = test_data.drop('ID', axis=1).values\n",
    "X_test = X_test.reshape(-1, 1, 32, 32) / 255.0  \n",
    "test_ids = test_data['ID']\n",
    "\n",
    "# to tensor pytorch\n",
    "test_tensor = TensorDataset(torch.Tensor(X_test))\n",
    "\n",
    "# DataLoader\n",
    "test_loader = DataLoader(test_tensor, batch_size=64, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "dae5c85b-7c1e-4aa3-8ad2-0bd44723567e",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = CustomCNN([64, 128])  \n",
    "model.load_state_dict(torch.load('final_best_model.pth'))\n",
    "model.eval()\n",
    "\n",
    "# collecting predictions\n",
    "predictions = []\n",
    "with torch.no_grad():\n",
    "    for inputs in test_loader:\n",
    "        outputs = model(inputs[0])\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        predictions.extend(predicted.tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "e6e2eb42-c477-421f-a6be-0a0e007a9665",
   "metadata": {},
   "outputs": [],
   "source": [
    "results_df = pd.DataFrame({\n",
    "    'ID': test_ids,\n",
    "    'label': predictions\n",
    "})\n",
    "\n",
    "#df to csv\n",
    "results_df.to_csv('results.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce5fb690-db22-40df-9e5a-aa03052ef23c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
